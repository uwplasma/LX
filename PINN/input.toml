[hyperparameter_optimization]
hpo_disable_plots = false
hpo_disable_ckpt  = false
hpo_disable_lbfgs = false

[surfaces]       # "single" | "torus" | "files"
mode = "files"   

# Each file item chooses one of:
#   format = "grid"   → expects X,Y,Z arrays (nθ×nφ) in .npz/.npy (keys: X,Y,Z)
#   format = "points" → expects P (N×3) in .npy/.npz/.csv/.txt
# Optionally provide normals_path pointing to Nb×3 normals; if absent, we estimate them.
#files = [
#  # Minimal: STL reads as a watertight triangulated mesh; normals+inside available.
#  { name = "W7X_like", path = "data/w7x_panel.stl", kind = "mesh", every = 2 },
#  { name = "HSX_like", path = "data/hsx_shell.stl", kind = "mesh", sample = 50000 },
#]
#files = [
#  { name = "ImportedCloud", path = "data/cloud_with_normals.csv", kind = "xyz",
#    xcol = 0, ycol = 1, zcol = 2, nxcol = 3, nycol = 4, nzcol = 5, units = 1.0 }
#]
#files = [
#  { name = "S1", path = "surf_grid_w7x.npz",   format = "grid",  periodic_theta=true, periodic_phi=true },
#  { name = "S2", path = "coil_shell.npy",      format = "points", normals_path = "" },
#  { name = "S3", path = "freeform.csv",        format = "points" }
#]
#files = [{ name = "pyQSC", path = "pyqsc_surface.csv", format = "points", normals_path = ""}]
#files = ["qsc_surfaces_from_api.npz"]
#files = [{ name = "preciseQA", path = "wout_precise_QA.csv", format = "points", normals_path = "wout_precise_QA_normals.csv", normals_mode = "provided"},
#         { name = "preciseQH", path = "wout_precise_QH.csv", format = "points", normals_path = "wout_precise_QH_normals.csv", normals_mode = "provided"},
#         { name = "LandremanSenguptaPlunk53", path = "wout_LandremanSenguptaPlunk_5.3.csv", format = "points", normals_path = "wout_LandremanSenguptaPlunk_5.3_normals.csv", normals_mode = "provided"}]
#files = [{ name = "preciseQA", path = "wout_precise_QA.csv", format = "points", normals_path = "wout_precise_QA_normals.csv", normals_mode = "estimate"}]
#files = [{ name = "preciseQA", path = "wout_precise_QA.csv", format = "points", normals_path = "wout_precise_QA_normals.csv", normals_mode = "provided"}]
#files = [{ name = "knotTube", path = "knot_tube.csv", format = "points", normals_path = "knot_tube_normals.csv", normals_mode = "provided"}]
#files = [{ name = "SLAM", path = "slam_surface.csv", format = "points", normals_path = "slam_surface_normals.csv", normals_mode = "provided"}]
files = [{ name = "SLAM", path = "slam_surface.csv", format = "points", normals_mode = "estimate"}] # , normals_path = "slam_surface_normals.csv"
#files = [{ name = "Mirror", path = "sflm_rm4.csv", format = "points", normals_path = "sflm_rm4_normals.csv", normals_mode = "provided"}]

torus_list = [
    { name = "T1", a0 = 0.35, a1 = 0.20, N_harm = 3 },
    { name = "T2", a0 = 0.30, a1 = 0.10, N_harm = 2 },
    { name = "T3", a0 = 0.40, a1 = 0.05, N_harm = 4 }]

[geometry]
R0 = 3.0      # major radius
a0 = 2.0      # minor radius base
a1 = 0.15     # minor radius modulation amplitude
N_harm = 4    # mode in a(φ) = a0 + a1 cos(N_harm φ)

[checkpoint]
path = "pinn_torus_model.eqx"  # model checkpoint file path

[batch]
interior = 2048  # interior points per step
boundary = 2048  # boundary points per step

[multi_valued]
kappa = 0.4613818989772501   # u_mv = kappa * atan2(y,x) / R0; 0 disables multi-valued part

[sampling]
N_in = 10000          # interior sample count
N_bdry_theta = 16     # boundary θ resolution
N_bdry_phi = 128       # boundary φ resolution
rng_seed = 9308
bdry_presample_mult = 24     # importance-sampling pre-pool multiplier

[regularization]
zero_mean_weight = 0.6097909498264109      # was hard-coded default via runtime

[model]
hidden_sizes = [32, 32, 32, 32]   # MLP hidden layer sizes
activation = "sin" # one of: tanh, gelu, sigmoid, silu, softplus, identity, sin
siren = true            # turn on true SIREN init/forward
siren_omega0 = 13.312137122010249     # standard choice from the SIREN paper
use_fourier = false            # turn positional encoding on/off
fourier_bands = [1.0, 2.0, 4.0, 8.0]   # frequency multipliers (in 1/R0 units)
fourier_scale = 6.283185307179586      # 2π (leave as-is; multiplied by band/R0)
R0_for_fourier = 1.0

[optimization]
steps = 1250
lr = 0.007452432076639419
lam_bc = 1.6619587277675008
log_every = 50
mini_epoch = 51
lam_warm = 7.797930707655971      # initial (warm-start) λ for boundary loss

lam_grad = 0.0                 # 0 disables gradient-matching
grad_target_backprop = false    # usually keep false at first

# --- LBFGS (polish) ---
lbfgs_steps = 10        # set 0 to disable; 200–500 is typical
lbfgs_tol = 1e-7
lbfgs_print_every = 50

# (optional caps; 0 = use all)
lbfgs_interior = 0     # per surface interior points used by LBFGS
lbfgs_boundary = 0     # per surface boundary points used by LBFGS
lbfgs_weighting = "equal" # reserved for future weighting policies

use_augmented_lagrangian = true   # false keeps old behavior
al_rho = 0.10042691431126322                      # penalty (ρ) for the AL quadratic term
al_update_every = 27              # how often to update λ_AL (in steps)
al_clip = 2.356655476660051                     # optional: clip |λ_AL| to this value; 0 disables

grad_clip_norm = 3.7947288413053117
weight_decay = 0.0018816505810457865          # decoupled WD in AdamW (set >0 to use)
#lr_warmup_steps = 0          # e.g., 200
lr_warmup_frac = 0.05 
lr_min_ratio = 0.13826597422534959         # cosine floor: lr_min = lr * lr_min_ratio
use_ema = false
ema_decay = 0.999                 # Polyak EMA decay
ema_eval = true                   # use EMA params for eval & LBFGS init

use_lookahead = false
lookahead_sync_period = 8        # k steps between slow-weight syncs
lookahead_slow_step = 0.307        # α (0..1), typical 0.5

lbfgs_l2 = 0.0

[optimization.lbfgs]
l2 = 0                  # was lbfgs_l2

[box]
# z-extent of the fixed sampling box (x,y are computed from geometry each run)
zmin = -0.8
zmax =  0.8
points_total = 200000
seed = 42

[plot]
cmap = "viridis"
figsize = [8.0, 4.5]